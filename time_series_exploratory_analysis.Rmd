---
title: "Watts Up CA: Models"
author: "Claire Boyd, Kathryn Link-Oberstar, Megan Moore, Eshan Prashar"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r}
suppressMessages({
  library(readxl)
  library(dplyr)
  library(forecast)
  library(tidyverse)
  library(tsibble)
  library(fpp)
  library(tseries)
  library(tidyr)
  options(scipen = 999) #this is to switch off the scientific notation
})

file_path <- 'data/sorted_electricity_consumption_data.xlsx'
sorted_data <- read_excel(file_path)
residential <- ts(as.numeric(sorted_data$RESIDENTIAL.Sales.Megawatthours), start = c(1990, 1), frequency = 12)
```

### Plotting residential consumption curve

```{r}
plot(residential)
```



## SUPPLEMENTARY DATA

### Monthly Temperature Data for all of California

```{r, results='hold'}
# Load the Monthly Temperature Data

temp_data <- read_excel('./data/ca_monthly_temp_data.xlsx')
temp_ts <- ts(temp_data$Value, frequency = 12, start=c(1990,1))
plot(temp_ts, ylab="Temperature", main="Monthly Average Temperature 1990-2023")
```

```{r, results=TRUE}
plot(decompose(temp_ts))
```

With the temperature data we do not seem to have a notable upward or downward trend, though from the decomposition it might be experiencing a slight positive trend. We see a consistent 12-month seasonal trend that seems to be additive in nature given that the amplitude of the variance is not growing from the looks of it.

Read in minimum temperatures.

```{r}
min_temp <- read_csv(url("https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/statewide/time-series/4/tmin/all/1/1990-2023.csv?base_prd=true&begbaseyear=1901&endbaseyear=2000"), skip = 4)

min_temp_ts <- ts(min_temp$`Value`, frequency = 12, start =c(1990,1), end=c(2023, 7))

plot(min_temp_ts)
```

Read in maximum temperatures.

```{r}
max_temp <- read_csv(url("https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/statewide/time-series/4/tmax/all/1/1990-2023.csv?base_prd=true&begbaseyear=1901&endbaseyear=2000"), skip = 4)

max_temp_ts <- ts(max_temp$`Value`, frequency = 12, start =c(1990,1), end=c(2023, 7)) # ending in July 2023 when consumption data ends

plot(max_temp_ts)
```

### Yearly Population Data

```{r}
pop_data <- read_excel('./data/ca_pop_1990_2022.xlsx', sheet="Data")
pop_ts <- ts(pop_data[2], frequency = 1, start=1990)
plot(pop_ts, ylab="Population (millions)", main="Population of California 1990-2022")
```

For the population data we see an upward trend that may be leveling off (would maybe need damping) , or this may be due to the effects of covid and will continue linearly increasing. There is no seasonality as these are annual population estimates.

### Unemployment Data

```{r}
unemp_data <- read_excel('./data/bls_cali_seasonal_adj_1990_2023.xlsx', 
                         sheet="Sheet1")

unemp_rate_ts <- ts(unemp_data$`unemployment rate`, frequency = 12, start =c(1990,1))
plot(unemp_rate_ts, ylab="Unemployment rate", main="Monthly unemployment rate in
     California 1990-2023")
```

\*\*\* General observations: - Almost at its lowest levels pre-Covid and post 2022 - Before Covid, peak was in 2009 - after the financial crisis of 2008. However, then, double-digit unemployed stayed till 2012 which hasn't happened after Covid. - Before 2008 recession, near double digit unemployement in 1992-93 due to national recession - job cuts in manufacturing

```{r}
plot(decompose(unemp_rate_ts))
```
### Precipitation Data

```{r}
cali_precip <- read_csv('./data/weather_exp/data_preci.csv')
precip_ts <- ts(cali_precip$`Value`, frequency = 12, start =c(1990,1), end=c(2023, 7)) # ending in July 2023 when consumption data ends

plot(precip_ts)
```

### Hot Days
```{r}
hot_days <- read_csv('./data/weather_exp/data_heat_days.csv')
hot_days_ts <- ts(hot_days$`Value`, frequency = 12, start =c(1990,1), end=c(2023, 7)) # ending in July 2023 when consumption data ends

plot(hot_days_ts)
```
### Cold Days

```{r}
cold_days <- read_csv('./data/weather_exp/data_cool_days.csv')
cold_days_ts <- ts(cold_days$`Value`, frequency = 12, start =c(1990,1), end=c(2023, 7)) # ending in July 2023 when consumption data ends

plot(cold_days_ts)
```
### Natural gas consumption Data
```{r}
n_gas <- read_csv('./data/natural_gas/California_Natural_Gas_Residential_Consumption.csv')
n_gas_ts <- ts(n_gas$`Value`, frequency = 12, start =c(1990,1), end=c(2023, 7)) # ending in July 2023 when consumption data ends

plot(n_gas_ts)
```
### Pricing

```{r}
elec_prices_ts <- ts(as.numeric(sorted_data$RESIDENTIAL.Price.Cents.kWh), start = c(1990, 1), frequency = 12)
plot(elec_prices_ts)
```

### Residential Customers Data
```{r}
customers <- read_excel('./data/customers_imputed.xlsx', sheet = "Sheet2")
customers_ts <- ts(customers$`customers`, frequency = 12, start =c(1990,1), end=c(2023, 7)) # ending in July 2023 when consumption data ends

plot(customers_ts)
```


## TRAIN TEST SPLITS

```{r}
#train/test split at 1990
train_res_1990 <- window(residential, start=1990, end=c(2022, 6))
test_res_1990 <- window(residential, start=c(2022, 7), end=c(2023, 7))
train_test_res_1990 <- window(residential, start=1990, end=c(2023, 7))

#train/test split at 2005
train_res_2005 <- window(residential, start=2005, end=c(2022, 6))
test_res_2005 <- window(residential, start=c(2022, 7), end=c(2023, 7))
train_test_res_2005 <- window(residential, start=1990, end=c(2023, 7))

#train/test split at 2013
train_res_2013 <- window(residential, start=2013, end=c(2022, 6))
test_res_2013 <- window(residential, start=c(2022, 7), end=c(2023, 7))
train_test_res_2013 <- window(residential, start=2013, end=c(2023, 7))
```

### Train-Test Splits for Independent Variables

```{r}
split_time_series <- function(time_series, year) {
  start_train <- c(year, 1)
  end_train <- c(2022, 6)
  start_test <- c(2022, 7)
  end_test <- c(2023, 7)
  start_train_test <- c(year, 1)
  end_train_test <- c(2023, 7)
  
  train_set <- window(time_series, start = start_train, end = end_train)
  test_set <- window(time_series, start = start_test, end = end_test)
  train_test_set <- window(time_series, start = start_train_test, end = end_train_test)
  
  return(list(train = train_set, test = test_set, train_test = train_test_set))
}
```

```{r}
# train test split for temp data
min_1990 <- split_time_series(min_temp_ts, 1990)
train_min_temp_1990 <- min_1990$train
test_min_temp_1990 <- min_1990$test
train_test_min_temp_1990 <- min_1990$train_test

min_2005 <- split_time_series(min_temp_ts, 2005) 
train_min_temp_2005 <- min_2005$train
test_min_temp_2005 <- min_2005$test
train_test_min_temp_2005 <- min_2005$train_test

min_2013 <- split_time_series(min_temp_ts, 2013) 
train_min_temp_2013 <- min_2013$train
test_min_temp_2013 <- min_2013$test
train_test_min_temp_2013 <- min_2013$train_test

max_1990 <- split_time_series(max_temp_ts, 1990) 
train_max_temp_1990 <- max_1990$train
test_max_temp_1990 <- max_1990$test
train_test_max_temp_1990 <- max_1990$train_test

max_2005 <- split_time_series(max_temp_ts, 2005) 
train_max_temp_2005 <- max_2005$train
test_max_temp_2005 <- max_2005$test
train_test_max_temp_2005 <- max_2005$train_test

max_2013 <- split_time_series(max_temp_ts, 2013) 
train_max_temp_2013 <- max_2013$train
test_max_temp_2013 <- max_2013$test
train_test_max_temp_2013 <- max_2013$train_test

## New additions

#temperature
avgtemp_1990 <- split_time_series(temp_ts, 1990) 
train_avgtemp_1990 <- avgtemp_1990$train
test_avgtemp_1990 <- avgtemp_1990$test
train_test_avgtemp_1990 <- avgtemp_1990$train_test


#unemployment rate
unemp_1990 <- split_time_series(unemp_rate_ts, 1990) 
train_unemp_1990 <- unemp_1990$train
test_unemp_1990 <- unemp_1990$test
train_test_unemp_1990 <- unemp_1990$train_test

# precipitation
precip_1990 <- split_time_series(precip_ts, 1990) 
train_precip_1990 <- precip_1990$train
test_precip_1990 <- precip_1990$test
train_test_precip_1990 <- precip_1990$train_test

# hot days
hdays_1990 <- split_time_series(hot_days_ts, 1990) 
train_hdays_1990 <- hdays_1990$train
test_hdays_1990 <- hdays_1990$test
train_test_hdays_1990 <- hdays_1990$train_test

# cold days
cdays_1990 <- split_time_series(cold_days_ts, 1990) 
train_cdays_1990 <- cdays_1990$train
test_cdays_1990 <- cdays_1990$test
train_test_cdays_1990 <- cdays_1990$train_test

# natural gas
ngas_1990 <- split_time_series(n_gas_ts, 1990) 
train_ngas_1990 <- ngas_1990$train
test_ngas_1990 <- ngas_1990$test
train_test_ngas_1990 <- ngas_1990$train_test

#pricing
elec_prices_1990 <- split_time_series(elec_prices_ts, 1990) 
train_elec_prices_1990 <- elec_prices_1990$train
test_elec_prices_1990 <- elec_prices_1990$test
train_test_elec_prices_1990 <- elec_prices_1990$train_test

# customers
customers_1990 <- split_time_series(customers_ts, 1990) 
train_customers_1990 <- customers_1990$train
test_customers_1990 <- customers_1990$test
train_test_customers_1990 <- customers_1990$train_test

```


## BASELINE MODELS

### Seasonal Naive baseline model

The point forecasts are the same for each of these models, but the information criteria estimates are different (and the confidence interval bands are different for each)

MAPE for 1990: 5.521388 RMSE for 1990: 562980.8

MAPE for 2005: 6.094906 RMSE for 2005: 657427

MAPE for 2013: 7.692256 RMSE for 2013: 797692.8

Both are increasing as we narrow the window size.

```{r}
snaive_model_1990 = snaive(train_res_1990, lambda='auto', h=12)
accuracy(snaive_model_1990)

snaive_model_2005 = snaive(train_res_2005, lambda='auto', h=12)
accuracy(snaive_model_2005)

snaive_model_2013 = snaive(train_res_2013, lambda='auto', h=12)
accuracy(snaive_model_2013)

plot(snaive_model_2013)
```

```{r}
Acf(snaive_model_1990$residuals, lag=100)
Pacf(snaive_model_1990$residuals, lag=100)
```

### Exponential Smoothing

model type: ETS(M,N,M) MAPE for 1990: 4.667398 RMSE for 1990: 466188.8

model type: ETS(M,N,A) MAPE for 2005: 5.300409 RMSE for 2005: 535969.3

model type: ETS(M,N,M) MAPE for 2013: 5.55343 RMSE for 2013: 573835.4

Weird that with different windows a different ETS model is being specified. Similar to seasonal naive, as we increase the size of training data, we increase the MAPE and RSME values.

```{r}
ets_model_1990 = ets(train_res_1990,lambda='auto')
summary(ets_model_1990)

ets_model_2005 = ets(train_res_2005,lambda='auto')
summary(ets_model_2005)

ets_model_2013 = ets(train_res_2013,lambda='auto')
summary(ets_model_2013)
```

```{r}
plot(forecast(ets_model_1990, h=12))
```

### Linear Regression

MAPE for 1990: 6.877424 RMSE for 1990: 610919.6

MAPE for 2005: 5.426142 RMSE for 2005: 533482.7

MAPE for 2013: 5.572336 RMSE for 2013: 570245.5

Unlike the other baselines, this slightly improves with time and then gets worse again.

```{r}
tslm_model_1990 = tslm(train_res_1990 ~ trend + season)
summary(tslm_model_1990)
accuracy(tslm_model_1990)

tslm_model_2005 = tslm(train_res_2005 ~ trend + season)
summary(tslm_model_2005)
accuracy(tslm_model_2005)

tslm_model_2013 = tslm(train_res_2013 ~ trend + season)
summary(tslm_model_2013)
accuracy(tslm_model_2013)
```

```{r}
Acf(tslm_model_1990$residuals)
pacf(tslm_model_1990$residuals)
```

```{r}
plot(forecast(tslm_model_1990, h=12))
```

```{r}
tslm_model_1990
```

### Auto Arima

```{r}
residential_auto_arima_1990 <- auto.arima(train_res_1990, 
                                     seasonal = TRUE, 
                                     allowdrift = TRUE, 
                                     lambda = 'auto')

summary(residential_auto_arima_1990)
checkresiduals(residential_auto_arima_1990)
accuracy(residential_auto_arima_1990)
plot(forecast(residential_auto_arima_1990, h=12))
```

-   Residuals are not white noise

```{r}
residential_auto_arima_2005 <- auto.arima(train_res_2005, 
                                     seasonal = TRUE, 
                                     allowdrift = TRUE, 
                                     lambda = 'auto')
summary(residential_auto_arima_2005)
checkresiduals(residential_auto_arima_2005)
accuracy(residential_auto_arima_2005)
plot(forecast(residential_auto_arima_2005, h=12))
```

```{r}
residential_auto_arima_2013 <- auto.arima(train_res_2013, 
                                     seasonal = TRUE, 
                                     allowdrift = TRUE, 
                                     lambda = 'auto')
summary(residential_auto_arima_2013)
checkresiduals(residential_auto_arima_2013)
accuracy(residential_auto_arima_2013)
plot(forecast(residential_auto_arima_2013, h=12))
```

```{r}
checkresiduals(residential_auto_arima_2013)
```



### Linear Regression with independent variables

```{r}
residential_multiv_reg_1990 <- tslm(train_res_1990 ~ train_max_temp_1990 + 
                  train_cdays_1990 + train_hdays_1990 + 
                  train_precip_1990 + train_ngas_1990 + train_elec_prices_1990 + 
                  train_customers_1990, lambda = 'auto')

# Store the residuals
residuals_residential_multiv_reg_1990 <- residuals(residential_multiv_reg_1990)

# Store the fitted values
fitted_residential_multiv_reg_1990 <- residential_multiv_reg_1990$fitted.values

summary(residential_multiv_reg_1990)
accuracy(residential_multiv_reg_1990)
```
### Baseline regression model analysis

```{r}
## Regression analysis: potential to create a function that does all of this for any given regression

# First, let's plot residuals vs. fitted values
plot(fitted_residential_multiv_reg_1990, residuals_residential_multiv_reg_1990, 
     xlab = "Fitted values", ylab = "Residuals", 
     main = "Residuals vs Fitted Values Plot")
abline(h = 0, col = "red")  # Add a horizontal line at y = 0 (for reference)

# What conclusion can be drawn from this? -> Residual values are pretty low, which is good I guess?

# Now, we can create a Q-Q plot for residuals 
qqnorm(residuals_residential_multiv_reg_1990)
qqline(residuals_residential_multiv_reg_1990)

# Shapiro-Wilk normality test
shapiro.test(residuals_residential_multiv_reg_1990)

# We can also check the ACF plot for residuals
checkresiduals(residential_multiv_reg_1990)
```

### Overall takeaways from baseline model:
- Adjusted R\^2? - Almost half the variation can be explained by these variables
- Plot of residuals vs. fitted values does not convey anything clearly
- QQ plot indicates significant deviation from normality; confirmed by Shapiro-Wilk test
- Breusch-Godfrey test and ACF plots also show clear auto-correlations in residuals


### Add Claire's tslm with just seasonality and trend here
MAPE for 1990: 5.77 RMSE for 1990: 520,087

### Adding trend and seasonality along with other variables
```{r}
residential_ts_multiv_reg_1990 <- tslm(train_res_1990 ~ trend + season + train_max_temp_1990 + 
                  train_cdays_1990 + train_hdays_1990 + 
                  train_precip_1990 + train_ngas_1990 + train_elec_prices_1990 + 
                  train_customers_1990, lambda = 'auto')

# Store the residuals
residuals_residential_ts_multiv_reg_1990 <- residuals(residential_ts_multiv_reg_1990)

# Store the fitted values
fitted_residential_ts_multiv_reg_1990 <- residential_ts_multiv_reg_1990$fitted.values

summary(residential_ts_multiv_reg_1990)
accuracy(residential_ts_multiv_reg_1990)
```

### MAPE value of 4.14 and RMSE value of 417,104 are better

### Baseline regression with trend and seasonality model analysis

```{r}

# First, let's plot residuals vs. fitted values
plot(fitted_residential_ts_multiv_reg_1990, residuals_residential_ts_multiv_reg_1990, 
     xlab = "Fitted values", ylab = "Residuals", 
     main = "Residuals vs Fitted Values Plot")
abline(h = 0, col = "red")  # Add a horizontal line at y = 0 (for reference)

# Now, we can create a Q-Q plot for residuals 
qqnorm(residuals_residential_ts_multiv_reg_1990)
qqline(residuals_residential_ts_multiv_reg_1990)

# Shapiro-Wilk normality test
shapiro.test(residuals_residential_ts_multiv_reg_1990)

# We can also check the ACF plot for residuals
checkresiduals(residential_ts_multiv_reg_1990)
```
## What changed?
- Residuals seem to be normally distributed
- However, they still have serial autocorrelation
- From this analysis, we can however narrow down to the important variables: 
  - trend, season, max_temp, cold_days, prices and customers

## Potential next steps for model building: 
- To forecast independent variables, use seasonal naive
- Megan already has Regression with ARIMA error, just make all variables stationary before running the models
- Check if residuals still show auto-correlation
- Check accuracy measures on train and test
- Plot forecasts with confidence intervals
- With this, our regression analysis should be complete

## MODEL 1: REGRESSION WITH ARMA ERRORS 

```{r}
residential_reg_w_arima_err_1990 <- auto.arima(train_res_1990, 
                                               xreg = cbind(train_min_temp_1990, train_max_temp_1990),
                                               seasonal = TRUE) # using lambda and drift made it look pretty whack

residential_reg_w_arima_err_2005 <- auto.arima(train_res_2005, 
                                               xreg = cbind(train_min_temp_2005, train_max_temp_2005),
                                               seasonal = TRUE) # using lambda and drift made it look pretty whack

residential_reg_w_arima_err_2013 <- auto.arima(train_res_2013, 
                                               xreg = cbind(train_min_temp_2013, train_max_temp_2013),
                                               seasonal = TRUE) # using lambda and drift made it look pretty whack
```

```{r}
summary(residential_reg_w_arima_err_1990)
summary(residential_reg_w_arima_err_2005)
summary(residential_reg_w_arima_err_2013)
checkresiduals(residential_reg_w_arima_err_1990)
checkresiduals(residential_reg_w_arima_err_2005)
checkresiduals(residential_reg_w_arima_err_2013)
```

```{r}
residential_reg_w_arima_err_1990_for <- forecast(residential_reg_w_arima_err_1990, h=12, xreg=cbind(test_min_temp_1990, test_max_temp_1990))

autoplot(residential_reg_w_arima_err_1990_for) +
  autolayer(test_res_1990)

residential_reg_w_arima_err_2005_for <- forecast(residential_reg_w_arima_err_2005, h=12, xreg=cbind(test_min_temp_2005, test_max_temp_2005))

autoplot(residential_reg_w_arima_err_2005_for) +
  autolayer(test_res_2005)

residential_reg_w_arima_err_2013_for <- forecast(residential_reg_w_arima_err_2013, h=12, xreg=cbind(test_min_temp_2013, test_max_temp_2013))

autoplot(residential_reg_w_arima_err_2013_for) +
  autolayer(test_res_2013)

plot(residential_reg_w_arima_err_1990_for)
plot(residential_reg_w_arima_err_2005_for)
plot(residential_reg_w_arima_err_2013_for)
```


## MODEL TESTING

*Models to Test*

```{r}
models <- list(
  list("Residential Auto Arima - 1990", residential_auto_arima_1990, train_res_1990, test_res_1990, 12),
  list("Residential Auto Arima - 2005", residential_auto_arima_2005, train_res_2005, test_res_2005, 12),
  list("Residential Auto Arima - 2013", residential_auto_arima_2013, train_res_2013, test_res_2013, 12),
  list("Residential Seasonal Naive - 1990", snaive_model_1990, train_res_1990, test_res_1990, 12),
  list("Residential Seasonal Naive - 2005", snaive_model_2005, train_res_2005, test_res_2005, 12),
  list("Residential Seasonal Naive - 2013", snaive_model_2013, train_res_2013, test_res_2013, 12),
  list("ETS - 1990", ets_model_1990, train_res_1990, test_res_1990, 12),
  list("ETS - 2005", ets_model_2005, train_res_2005, test_res_2005, 12),
  list("ETS - 2013", ets_model_2013, train_res_2013, test_res_2013, 12),
  list("Linear Regression - 1990", tslm_model_1990, train_res_1990, test_res_1990, 12),
  list("Linear Regression - 2005", tslm_model_2005, train_res_2005, test_res_2005, 12),
  list("Linear Regression - 2013", tslm_model_2013, train_res_2013, test_res_2013, 12),
  list("Regression with ARIMA Errors - 1990", residential_reg_w_arima_err_1990, train_res_1990, test_res_1990, 12, cbind(test_min_temp_1990, test_max_temp_1990)), 
  list("Regression with ARIMA Errors - 2005", residential_reg_w_arima_err_2005, train_res_2005, test_res_2005, 12, cbind(test_min_temp_2005, test_max_temp_2005)),
  list("Regression with ARIMA Errors - 2013", residential_reg_w_arima_err_2013, train_res_2013, test_res_2013, 12, cbind(test_min_temp_2013, test_max_temp_2013))
)
```

*Training Metrics*

```{r}
evaluate_models_train <- function(models) {
  results <- list()
  
  for (model_info in models) {
    
    model_name <- model_info[[1]]
    model <- model_info[[2]]
    train_data <- model_info[[4]]
    test_data <- model_info[[4]]
    horizon <- model_info[[5]]
    
    errors <- accuracy(model)
    MAPE <- errors["Training set", "MAPE"]
    RMSE <- errors["Training set", "RMSE"]
    AICc <- ifelse(exists("aicc", where = model), model$aicc, NA)
    
    results[[model_name]] <- list(MAPE = MAPE, RMSE = RMSE, AICc = AICc)

    cat(paste0(model_name, " Model Performance on Training Data: \n",
               "MAPE: ", MAPE, "\n",
               "RMSE: ", RMSE, "\n",
               "AICc: ", AICc, "\n\n"))
  }

  return(results)
}

results_training <- evaluate_models_train(models)
```

*Testing Metrics*

```{r}
evaluate_models_test <- function(models) {
  results <- list()
  
  for (model_info in models) {
    
    model_name <- model_info[[1]]
    model <- model_info[[2]]
    train_data <- model_info[[4]]
    test_data <- model_info[[4]]
    horizon <- model_info[[5]]
    if (length(model_info) >= 6){
      xreg_val <- model_info[[6]]
      model_forecast <- forecast(model, xreg=xreg_val, h=horizon)
    } else {
      model_forecast <- forecast(model, h=horizon)
    }
    
    errors <- accuracy(model_forecast, test_data)
    MAPE <- errors["Test set", "MAPE"]
    RMSE <- errors["Test set", "RMSE"]
    AICc <- ifelse(exists("aicc", where = model), model$aicc, NA)
    
    results[[model_name]] <- list(MAPE = MAPE, RMSE = RMSE, AICc = AICc, Forecast = model_forecast)
    
    cat(paste0(model_name, " Model Performance on Test Data: \n",
               "MAPE: ", MAPE, "\n",
               "RMSE: ", RMSE, "\n",
               "AICc: ", AICc, "\n\n"))
  }
  
  return(results)
}

results <- evaluate_models_test(models)
```
